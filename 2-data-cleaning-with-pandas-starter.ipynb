{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PREPROCESSING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# makes the dataframes easier to view. Just formatting.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TITLE -->\n",
    "# 1.0 Read in the CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- INTRODUCTION -->\n",
    "## Working with incorrect data and missing values\n",
    "\n",
    "While the Boston dataset we loaded from the sklearn datasets is great for practicing using pandas, it's not likely you'll find data that's perfectly clean in the real world. In this lesson we'll review some methods and techniques for working with incomplete or missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 1.1 -->\n",
    "## Read in the new csv file\n",
    "\n",
    "In the example below we will read in the same dataset with some manufactured issues in it to learn how to clean a dataset. First we will read in the csv using the pandas `.read_csv()` module. When reading in a file from your local computer you have to specify the file path that you're pulling the data from. If your information is located in the downloads folder in your home directory the filepath would look something like this `'./my_interesting_file.csv'`, where the . represents the current directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 1.1\n",
    "# Read in the csv file to a variable named boston_dirty_df\n",
    "\n",
    "# Check the columns attribute and printing that to output to see which\n",
    "# columns have changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT 1.1 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Remember to use `pd.read_csv()` and then pass in the filename. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 1.2 -->\n",
    "## Clean up the column names\n",
    "\n",
    "Once we've read the file in you'll notice that there are some incorrect column names. Since we know what the column names are supposed to be from previous examples we can fix that easily. There are two ways we'll show you how to correct this. One way is to pass a list of values and set that equal to the dataframe's columns attribute e.g. `boston_df.columns = ['CRIM', 'ZN', 'RM', ...]`. Another way is to selectively rename the columns by passing a dictionary through to the columns parameter of the rename function in pandas e.g `boston_df.replace(columns={'old_name': 'new_name'})`. Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 1.2\n",
    "# Check the columns attribute and printing that to output to see which\n",
    "# columns have changed\n",
    "\n",
    "\n",
    "# Use one or both of the methods above to rename the columns appropriately.\n",
    "# Correct column names for reference [u'CRIM', u'ZN', u'INDUS', u'CHAS', u'NOX',\n",
    "# u'RM', u'AGE', u'DIS', u'RAD', u'TAX', u'PTRATIO', u'B', u'LSTAT']'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT 1.2 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Remember to pass a dictionary of old and new name pairs into the `columns` argument if using the `.rename()` function and a list if passing directly to the `columns` argument. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TITLE -->\n",
    "# Imputing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- INTRODUCTION -->\n",
    "## Imputing missing values\n",
    "\n",
    "In this task we'll look at one of the columns that contains missing values and will work to replace those values with the mean value from the rest of the column. When working with a dataframe the `.isnull()` method is very useful for seeing where there are `NaN` (not a number) or missing values. Calling `.isnull()` on the dataframe itself will yield a dataframe with boolean values indicating whether the cell is null or not. We can then call the `.sum()` function to count the number of null values at each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 2.1 -->\n",
    "In this instance we'll take the mean value of the entire column and use it to replace the `NaN` values. We can also compute the minimum and maximum values in a column using `.max()` or `.min()`, and replace `NaN`s with these. Choosing which approach to take requires careful consideration, and the right choice depends on the dataset and problem to be solved. Later, we'll go through other strategies to deal with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 2.1\n",
    "# call .isnull() and .sum() to get the total number of null values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT 2.1 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Remember to call `.isnull()` on the DataFrame first followed by `.sum()` all in one line. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 2.2 -->\n",
    "To impute the missing values, call `.fillna()`, and pass in the mean of the column's values. Then we'll assign this value to the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STARTER CODE for 2.2\n",
    "# step 1: Use .mean() to find the mean value of the 'CRIM' column\n",
    "# step 2: The output of this value should be passed through to the .fillna() method\n",
    "# step 3: Assign the the output of both of those calculations to the 'CRIM' column\n",
    "# or use inplace=True to write directly to the dataframe\n",
    "\n",
    "# call the same .isnull() and .sum() combination again to see if the operation\n",
    "# was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT 2.2 -->\n",
    "#### Double Click for Hint\n",
    "<!-- The suggested format for filling in values to the 'CRIM' column: `boston_df.column_name = boston_df.fillna(boston_df.column_name.mean())`. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 2.3 -->\n",
    "You may have noticed in the last task that the LSTAT column has 395 missing values. In some instances you may have such little data that the column is unusable for modeling or analysis. It certainly wouldn't be wise to try and calculate the mean value and fill the missing 395 values with only 100 or so actual data points. In the following exercise we'll delete the LSTAT row.\n",
    "\n",
    "For illustrative purposes, we'll delete the row in place so you learn how, but it usually makes sense to create a new copy of the dataframe, separate from the original, and slice out the bad column there.\n",
    "\n",
    "One thing to note is that you should only run the cell to delete the column once. If you've already deleted the column then when you run the cell it will try and delete a column that no longer exists on the dataframe and will throw an exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 3.1 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STARTER CODE for 2.3\n",
    "# del df['col_name'] where df and col_name are the DataFrame and column names you're trying to delete\n",
    "# reoutput the dataframe so you can ensure it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 2.3 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Remember one method to access a specific column in a dataframe is df['col_name'] -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 3.4 -->\n",
    "## Dropping NaN values\n",
    "\n",
    "As we saw previously, one approach to dealing with `NaN` values in a column is to replace them with the mean. Another approach is simply to drop the values altogether. Again, choosing the right technique requires some thought, and you shouldn't rush to simply drop data or impute the mean value without considering the implications. It can be important to know when to choose each. To demonstrate, we'll use the `.dropna()` function to drop all the remaining `NaN` values from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 3.4\n",
    "# use .dropna() and set the parameters axis=0 and inplace=True\n",
    "# check to see if there are any null values left by using .isnull() and .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.4 -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TITLE -->\n",
    "## Converting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- INTRODUCTION -->\n",
    "Now that we've removed all the `NaN` values, we need to check the data types for each column  with the `.dtypes` attribute to see if they're what we expect. Notice that most of the columns are of type `float64` or `int64`, which is convenient because linear regression requires numeric data. However, you'll notice there are a few columns that have `object` data types, such as 'CRIM'. This indicates that the column contains multiple incompatible datatypes that could not be combined when reading from the .csv file, so the column gets assigned the most general type, `object`.\n",
    "Since we know the 'CRIM' column should be of type `float`, we can convert it using `.astype()`.\n",
    "\n",
    "Note that by default, `.astype()` creates a copy of the column it operates on. So far we've been overwriting data in place in `boston_dirty_df`, so we'll override this default with the 'copy' argument. In general, you would should create copies of the original data so that if you accidentally overwrote something incorrectly, you wouldn't have to re-import from .csv. However, for simplicity, we'll continue overwriting in the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 3.1 -->\n",
    "Use `.astype()` to convert the 'CRIM' column to `float`. Note that `.astype()` creates a copy of the column it operates on, so you must replace the original column with the newly created copy. To accomplish this either set `copy = False` or set the column name equal to the new copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX         object\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD          int64\n",
       "TAX         object\n",
       "PTRATIO     object\n",
       "B          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STARTER CODE for 3.1\n",
    "boston_dirty_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.1 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 3.2 -->\n",
    "## Using regex to find alphabetic characters in columns\n",
    "\n",
    "The `.astype()` function is very useful for converting between compatible datatypes, but it has limitations. What happens when you try to convert the string 'a' or 'b' to a `float` or `int`? Is this even possible? If you try  `.astype('float')` on a column that contains strings, the function will raise an exception. Specifically if you tried this on the 'NOX' column you would get the following error: `ValueError: could not convert string to float: a`. One way to get around this is to replace the value of those cells with the mean value of the rest of the column. Another would be to just drop the rows with the wrongly formatted data. We'll explore both approaches.\n",
    "\n",
    "In the below example we'll be using Regular Expressions or regex to find the alphabetic characters. There are a ton of other interesting and powerful things you can do with regex but we'll start basic. The code below searches the 'NOX' column for any alphabetic characters from A-Z for uppercase and a-z for lowercase. It returns boolean array the same length as the 'NOX' column where 'True' means there was an a letter (A-Z or a-z) in that cell and 'False' means there wasn't. When we pass this array in to the original dataframe, we're filtering, or masking, the dataframe to only show the values in a `True` cell. The end result is a dataframe that shows which rows had letters in the 'NOX' column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21</td>\n",
       "      <td>288.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>am</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21</td>\n",
       "      <td>303.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.08387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>5.874</td>\n",
       "      <td>36.6</td>\n",
       "      <td>4.5026</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>6.630</td>\n",
       "      <td>56.1</td>\n",
       "      <td>4.4377</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>18.5</td>\n",
       "      <td>392.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>7.007</td>\n",
       "      <td>86.3</td>\n",
       "      <td>3.4217</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM   ZN  INDUS  CHAS NOX     RM   AGE     DIS  RAD  TAX PTRATIO  \\\n",
       "18  0.80271  0.0   8.14   0.0   b  5.456  36.6  3.7965    4  307      21   \n",
       "25  0.84054  0.0   8.14   0.0  am  5.599  85.7  4.4546    4  307      21   \n",
       "76  0.10153  0.0  12.83   0.0   a  6.279  74.5  4.0522    5  398    18.7   \n",
       "79  0.08387  0.0  12.83   0.0   a  5.874  36.6  4.5026    5  398    18.7   \n",
       "85  0.05735  0.0   4.49   0.0   a  6.630  56.1  4.4377    3    a    18.5   \n",
       "88  0.05660  0.0   3.41   0.0   a  7.007  86.3  3.4217    2  270    17.8   \n",
       "\n",
       "         B  \n",
       "18  288.99  \n",
       "25  303.42  \n",
       "76  373.66  \n",
       "79  396.06  \n",
       "85  392.30  \n",
       "88  396.90  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STARTER CODE for 3.2\n",
    "\n",
    "# run once to see output\n",
    "\n",
    "# search the NOX column for alphabetic characters\n",
    "letter_mask = boston_dirty_df.NOX.str.contains(r'[A-Za-z]', regex=True)\n",
    "\n",
    "# pass the boolean array into the original dataframe to return a dataframe\n",
    "# where the values are True\n",
    "boston_dirty_df[letter_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.2 -->\n",
    "Just run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 3.3 -->\n",
    "## Create an new list of the index values for our filtered dataframe\n",
    "\n",
    "Here we will use the `.index` attribute to pull out the index values from our newly created dataframe containing the alphabetic characters. We'll be doing this so that we can reference those values later on and replace the alphabetic characters with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 3.3\n",
    "\n",
    "# search the NOX column for alphabetic characters\n",
    "letter_mask = boston_dirty_df.NOX.str.contains(r'[A-Za-z]', regex=True)\n",
    "\n",
    "# pass the boolean array into the original dataframe to return a dataframe\n",
    "# where the values are True\n",
    "boston_dirty_df[letter_mask]\n",
    "\n",
    "# use the index attribute and create a new list with list() of the index values\n",
    "# save this to a new variable named index_list for later on in the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 3.4 -->\n",
    "## Use the ~ character to return all the False values\n",
    "\n",
    "In the task below use the `~` before the letter_mask variable to return the opposite of the original dataframe we requested. In this case if we pass `~letter_mask` in as a boolean filter to our dataframe it will return all the `False` values or all the values that contain no alphabetic characters. Then specify that we want to only return the 'NOX' column by passing 'NOX' in between two brackets at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.4 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Passing something like boston_dirty_df[~letter_mask]['NOX'] should work! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.4 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 3.5 -->\n",
    "## Convert the remaining values to float and find the mean\n",
    "\n",
    "Now that we have a way to filter by values that should all be numeric, we can convert them to `float` and calculate the mean. In the below code call the `.astype()` method to convert the values to `float` and then call the `.mean()` method to take the mean of those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE for 3.5\n",
    "\n",
    "# convert NOX column to a float type and calculate the mean value.\n",
    "# save this mean value to a new variable nox_mean\n",
    "nox_mean = boston_dirty_df[~letter_mask]['NOX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 3.6 -->\n",
    "## Use the index list we created to replace the strings with the mean value from the column\n",
    "\n",
    "Now that we have the index locations of the strings we want to replace and the mean value for the 'NOX' column, we can replace the values we are looking for. We can now write a simple function that iterates over the index list(`index_list`) that we created earlier and replace each value at that location (`.loc[]`) with the mean value we calculated above e.g. `for i in index_list: example_df.loc[i, 'col_name'] = mean_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    0.554635\n",
       "25    0.554635\n",
       "76    0.554635\n",
       "79    0.554635\n",
       "85    0.554635\n",
       "88    0.554635\n",
       "Name: NOX, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STARTER CODE for 3.6\n",
    "\n",
    "# check the values at the index locations to ensure we've replaced them correctly\n",
    "boston_dirty_df.loc[index_list, 'NOX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 3.6 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Remember the format of a for loop and use the appropriate names: `for i in index_list: example_df.loc[i, 'col_name'] = mean_value` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK for 3.7 -->\n",
    "## Convert the entire column to a float\n",
    "\n",
    "Now that we've replaced the string characters with values the `.astype()` method can actually convert, we can go back to our original goal of turning the entire column to floats. Use the `.astype()` module to convert the 'NOX' column all to floats now. Make sure to assign the new copy to the original dataframe or to specify `copy = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21</td>\n",
       "      <td>288.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>am</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21</td>\n",
       "      <td>303.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.08387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>5.874</td>\n",
       "      <td>36.6</td>\n",
       "      <td>4.5026</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.05735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>6.630</td>\n",
       "      <td>56.1</td>\n",
       "      <td>4.4377</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>18.5</td>\n",
       "      <td>392.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.05660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "      <td>7.007</td>\n",
       "      <td>86.3</td>\n",
       "      <td>3.4217</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM   ZN  INDUS  CHAS NOX     RM   AGE     DIS  RAD  TAX PTRATIO  \\\n",
       "18  0.80271  0.0   8.14   0.0   b  5.456  36.6  3.7965    4  307      21   \n",
       "25  0.84054  0.0   8.14   0.0  am  5.599  85.7  4.4546    4  307      21   \n",
       "76  0.10153  0.0  12.83   0.0   a  6.279  74.5  4.0522    5  398    18.7   \n",
       "79  0.08387  0.0  12.83   0.0   a  5.874  36.6  4.5026    5  398    18.7   \n",
       "85  0.05735  0.0   4.49   0.0   a  6.630  56.1  4.4377    3    a    18.5   \n",
       "88  0.05660  0.0   3.41   0.0   a  7.007  86.3  3.4217    2  270    17.8   \n",
       "\n",
       "         B  \n",
       "18  288.99  \n",
       "25  303.42  \n",
       "76  373.66  \n",
       "79  396.06  \n",
       "85  392.30  \n",
       "88  396.90  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STARTER CODE for 3.7\n",
    "\n",
    "# once it's run check the dtypes to ensure the NOX column is now all floats\n",
    "boston_dirty_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TITLE -->\n",
    "## Using replace to remove values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- INTRODUCTION -->\n",
    "The above example is a lot of work for such little payoff. If we're working with large datasets it can sometimes be much easier and much more valuable to just drop the values that can't be converted. Next we'll work through replacing the alphabetic values with the `.replace()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 4.1 -->\n",
    "Somewhere in the 'TAX' column there's a string 'a' that's preventing us from just using `.astype()` to convert the entire column to a float. Use the `.replace()` function to replace 'a' with `np.nan` which is just a NaN value from the numpy library. Also set the `inplace` parameter to True. The structure of `.replace()` is `example_df.replace('value_to_replace', 'value_to_substitute_in', inplace=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE\n",
    "\n",
    "# run to see if you've created new null values\n",
    "boston_dirty_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 4.1 -->\n",
    "#### Double Click for Hint\n",
    "<!-- Use `np.nan` as the value to substitute in. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 4.2 -->\n",
    "# Use regex to replace values\n",
    "\n",
    "The code we previously ran is great if we know what the values are we need to replace. In most instances we won't know what value we need to replace or there will be so many that doing this on a case by case basis is not feasible. In those cases it's probably easiest to use some regex to filter by alphabetic characters. In this example substitute the 'a' string with a regex for all alphabetic characters and set the regex parameter in the replace function equal to True. You should see that we've created a few more NaN values in the TAX and PTRATIO columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE\n",
    "\n",
    "# run to see if you've created new null values\n",
    "boston_dirty_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 4.1 -->\n",
    "#### Double Click for Hint\n",
    "<!-- The regex for alphabetic characters looks something like this `r'[A-Za-z]'` also don't forget to set `regex=True`. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TASK 4.3 -->\n",
    "# Drop the NaN values\n",
    "\n",
    "As we've done before, now we're going to drop the NaN values we've just created. Use the `.dropna()` function on the entire dataframe to drop all the remaining NaN values. Set `inplace=True` as a parameter to `.dropna()` to keep working with the same dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STARTER CODE\n",
    "\n",
    "# run to see if you've removed all NaN values\n",
    "boston_dirty_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- HINT for 4.2 -->\n",
    "#### Double Click for Hint\n",
    "<!-- The regex for alphabetic characters looks something like this `r'[A-Za-z]'`. Also don't forget to set `regex=True`. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- CONCLUSION -->\n",
    "Congratulations, you've worked through a few very common problems when dealing with datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Helpful Data Cleaning Functions Not Covered Above\n",
    "* pd.notnull() - Opposite of s.isnull() \n",
    "* df.dropna(axis=1) - Drop all columns that contain null values\n",
    "* s.replace([1,3],['one','three']) - Replace all 1 with 'one' and 3 with 'three' \n",
    "* df.rename(columns=lambda x: x + 1) - mass renaming of columns \n",
    "* df.set_index('column_one') - change the index \n",
    "* df.rename(index=lambda x: x + 1) - mass renaming of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
